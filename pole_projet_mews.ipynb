{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "ffTrzZkhhJAQ"
      },
      "id": "ffTrzZkhhJAQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b239e40f",
      "metadata": {
        "id": "b239e40f"
      },
      "outputs": [],
      "source": [
        "#libraries import\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "try:\n",
        "  from unidecode import unidecode\n",
        "except:\n",
        "  !pip install unidecode\n",
        "  from unidecode import unidecode\n",
        "from scipy.stats import norm\n",
        "from datetime import datetime\n",
        "\n",
        "from openpyxl.utils.cell import column_index_from_string, get_column_letter\n",
        "from openpyxl import load_workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "from openpyxl.styles import NamedStyle\n",
        "import openpyxl\n",
        "\n",
        "import shutil\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer upload de um arquivo\n",
        "uploaded = files.upload()\n",
        "\n",
        "!mkdir -p Mews_Partners\n",
        "\n",
        "# Mover o arquivo para um diretório específico\n",
        "shutil.move(list(uploaded.keys())[0], '/content/Mews_Partners/')"
      ],
      "metadata": {
        "id": "_TTBCG2z4OF4"
      },
      "id": "_TTBCG2z4OF4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "uPabMt2rhOP_"
      },
      "id": "uPabMt2rhOP_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90402430",
      "metadata": {
        "id": "90402430"
      },
      "outputs": [],
      "source": [
        "def fix_column_names(df):\n",
        "    dict_fix = {'.':' ','-':' ','/':' ',' ':'_'}\n",
        "    column_names = df.columns\n",
        "    new_column_names = []\n",
        "    for col in column_names:\n",
        "        # Remove accents and special characters\n",
        "        fixed_col = unidecode(col)\n",
        "        for char in dict_fix:\n",
        "            fixed_col = fixed_col.replace(char, dict_fix[char])\n",
        "        new_column_names.append(fixed_col)\n",
        "    return new_column_names\n",
        "\n",
        "def classeABCQuantity(df, qty_col_name, price_col_name):\n",
        "    # sum of quantities sold in each year\n",
        "    df = df[df[qty_col_name]!=0].reset_index(drop=True)\n",
        "    df_total_qty = df.groupby(['Code', 'Year'])[qty_col_name].sum().reset_index()\n",
        "    df_total_price = df.groupby(['Code', 'Year'])[price_col_name].sum().reset_index()\n",
        "\n",
        "    # cumulative sum for each year\n",
        "    df_total_qty = df_total_qty.sort_values(['Year',qty_col_name], ascending=[True, False])\n",
        "    df_total_qty['Cumulative_Sum'] = df_total_qty.groupby('Year')[qty_col_name].cumsum()\n",
        "    df_total_qty['Cumulative_Percentage'] = df_total_qty['Cumulative_Sum'] / df_total_qty.groupby('Year')[qty_col_name].transform('sum')\n",
        "\n",
        "    # classify the product in classes A,B and C\n",
        "    df = pd.merge(df, df_total_qty[['Code', 'Year', 'Cumulative_Percentage']], on=['Code', 'Year'])\n",
        "    abc_categories = pd.cut(df['Cumulative_Percentage'], bins=[0, 0.8, 0.95, 1.0], labels=['A', 'B', 'C'])\n",
        "    df['Classe_ABC_quantity'] = abc_categories\n",
        "\n",
        "    # cumulative sum for each year\n",
        "    df_total_price = df_total_price.sort_values(['Year',price_col_name], ascending=[True, False])\n",
        "    df_total_price['Cumulative_Sum_revenue'] = df_total_price.groupby('Year')[price_col_name].cumsum()\n",
        "    df_total_price['Cumulative_Percentage_revenue'] = df_total_price['Cumulative_Sum_revenue'] / df_total_price.groupby('Year')[price_col_name].transform('sum')\n",
        "\n",
        "    # classify the product in classes A,B and C\n",
        "    df = pd.merge(df, df_total_price[['Code', 'Year', 'Cumulative_Percentage_revenue']], on=['Code', 'Year'])\n",
        "    abc_categories = pd.cut(df['Cumulative_Percentage_revenue'], bins=[0, 0.8, 0.95, 1.0], labels=['A', 'B', 'C'])\n",
        "    df['Classe_ABC_revenue'] = abc_categories\n",
        "\n",
        "    return df\n",
        "\n",
        "def fix_dates(df):\n",
        "  # change date format\n",
        "  df['Date'] = df['Year'].astype(str) + '-' + df['Month'].astype(str)\n",
        "  df.Date = pd.to_datetime(df.Date, format='%Y-%m')\n",
        "  return df$\n",
        "\n",
        "def calculate_delay(df, list_col):\n",
        "  # calculating the delay time\n",
        "  dict_time = {'jrs': 1/30, 'semaine': 7/30, 'semaines': 7/30, 'mois':1}\n",
        "  for col in list_col:\n",
        "    df[col] = df[col].map(lambda x: x.split())\n",
        "    df[col] = df[col].map(lambda x: int(x[0])*dict_time[x[1]])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data"
      ],
      "metadata": {
        "id": "P2AbowDbQkV_"
      },
      "id": "P2AbowDbQkV_"
    },
    {
      "cell_type": "code",
      "source": [
        "# importing data\n",
        "df_base_prev_passe_original = pd.read_excel('Mews_Partners/DataModeleComplet.xlsx', header=2, sheet_name = 'Previsions_historique').iloc[1:, 3:]\n",
        "df_base_historique_original = pd.read_excel('Mews_Partners/DataModeleComplet.xlsx', header=3, sheet_name = 'Ventes_historique').iloc[:, 2:]\n",
        "df_flux_original = pd.read_excel('Mews_Partners/DataModeleComplet.xlsx', header=2, sheet_name = 'Baseflux').iloc[1:, 2:]\n",
        "df_base_article_original = pd.read_excel('Mews_Partners/DataModeleComplet.xlsx', header=1, sheet_name = 'Basearticle')\n",
        "df_stock_original = pd.read_excel('Mews_Partners/DataModeleComplet.xlsx', header=3, sheet_name = 'Stocks').iloc[:, 2:]"
      ],
      "metadata": {
        "id": "nbncrFHPmpAq"
      },
      "id": "nbncrFHPmpAq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis"
      ],
      "metadata": {
        "id": "CyEj6d_zajLf"
      },
      "id": "CyEj6d_zajLf"
    },
    {
      "cell_type": "code",
      "source": [
        "# Copying the original DataFrame\n",
        "df_base_prev_passe = df_base_prev_passe_original.copy()\n",
        "\n",
        "# Renaming columns\n",
        "new_cols = ['Code', 'Marche', 'Canal', 'Code_Magasin', 'Year', 'Month', 'Forecast_Magasin']\n",
        "df_base_prev_passe.columns = new_cols\n",
        "\n",
        "# Copying and fixing data types for the DataFrame\n",
        "df_base_prev = df_base_prev_passe.copy()\n",
        "df_base_prev.Code = df_base_prev.Code.astype(int)\n",
        "df_base_prev.Year = df_base_prev.Year.astype(int)\n",
        "df_base_prev.Month = df_base_prev.Month.astype(int)\n",
        "\n",
        "# Replacing values in the DataFrame\n",
        "df_base_prev = df_base_prev.replace(\"nan\", \"\").replace(\"-\", \"\")\n",
        "\n",
        "# Copying and renaming columns for the historical DataFrame\n",
        "df_base_historique = df_base_historique_original.copy()\n",
        "df_base_historique.rename(columns={'Code article ': 'Code', 'Marché': 'Marche', 'Code point de stock': 'Code_Magasin',\n",
        "                                   'Année': 'Year', 'Mois ': 'Month', 'Quantité': 'Historique_vente_Magasin'}, inplace=True)\n",
        "\n",
        "# Replacing values in the DataFrame\n",
        "df_base_historique = df_base_historique.replace(\"nan\", \"\")\n",
        "df_base_historique.Canal = df_base_historique.Canal.astype(str)\n",
        "df_base_historique.Code = df_base_historique.Code.astype(int)\n",
        "df_base_historique.Year = df_base_historique.Year.astype(int)\n",
        "df_base_historique.Month = df_base_historique.Month.astype(int)\n",
        "\n",
        "# Copying and renaming columns for the flux DataFrame\n",
        "df_flux = df_flux_original.copy()\n",
        "list_cols_names_flux = ['Code', 'Marche','Canal','Delay_Magasin','Frequency_Magasin','MOQ_Magasin','Code_Magasin','Delay_France','Frequency_France',\n",
        "                        'MOQ_France','Code_France','Delay_Monde','Frequency_Monde','MOQ_Monde','Code_Monde', 'Delay_Usine','Frequency_Usine','MOQ_Usine','Code_Usine']\n",
        "df_flux.columns = list_cols_names_flux\n",
        "df_flux = df_flux.replace(\"-\", \"\")\n",
        "\n",
        "# Copying, fixing column names, and data types for the article DataFrame\n",
        "df_base_article = df_base_article_original.iloc[:, 1:].copy()\n",
        "df_base_article.columns = fix_column_names(df_base_article)\n",
        "df_base_article = df_base_article.rename(columns={'Code_article': 'Code', 'Classe_': 'Classe_base'})\n",
        "\n",
        "# Copying and renaming columns for the stock DataFrame\n",
        "df_stock = df_stock_original.copy()\n",
        "df_stock.rename(columns={'Article': 'Code', 'Site ': 'Entrepot', 'Année': 'Year', 'Mois': 'Month'}, inplace=True)\n",
        "\n",
        "# Merging DataFrames and fixing dates\n",
        "df_base_prev_ventes = df_base_prev[['Code', 'Marche', 'Year', 'Month', 'Forecast_Magasin']].merge(df_base_historique, on=['Code', 'Marche', 'Year', 'Month'])\n",
        "df_base_prev_ventes = fix_dates(df_base_prev_ventes)\n",
        "df_stock = fix_dates(df_stock).drop(['Year', 'Month'], axis=1)\n",
        "\n",
        "# Merging DataFrames and fixing entrepôt names\n",
        "list_marche = {'France': 'FR', 'Belgique': 'BE', 'Belgium': 'BE', 'Spain': 'ES', 'Turkey': 'TK', 'Germany': 'DE',\n",
        "                  'Portugal': 'PT', 'Italy': 'IT', 'UK': 'UK', 'Swiss': 'CH', 'Poland': 'PL'}\n",
        "list_entrepot = {'FR': 'Central', 'BE': 'Central', 'TK': 'Central'}\n",
        "\n",
        "df_temp = df_base_prev_ventes.copy()\n",
        "df_temp['Marche'] = df_temp['Marche'].replace(list_marche)\n",
        "df_temp['Entrepot'] = df_temp['Marche'].replace(list_entrepot)\n",
        "\n",
        "\n",
        "df_prev_ventes_stock = df_temp.merge(df_stock, on=['Code', 'Date','Entrepot'])\n",
        "\n",
        "df_flux['Marche'] = df_flux['Marche'].replace(list_marche)\n",
        "\n",
        "# Filtering out rows with Code 'Loading...'\n",
        "df_flux = df_flux[df_flux.Code != \"Loading...\"]\n",
        "df_prev_ventes_stock = df_prev_ventes_stock[df_prev_ventes_stock.Code != \"Loading...\"]"
      ],
      "metadata": {
        "id": "J5OdaACYQnEq"
      },
      "id": "J5OdaACYQnEq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fix flux As-Is table"
      ],
      "metadata": {
        "id": "kEjeqtnbm64j"
      },
      "id": "kEjeqtnbm64j"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of markets where the Entrepot is 'Central'\n",
        "list_not_local_entrepot = ['FR', 'BE','TK']\n",
        "\n",
        "# Filter and select columns for the local DataFrame\n",
        "df_flux_local = df_flux.loc[~(df_flux.Marche.isin(list_not_local_entrepot)), ['Code', 'Marche', 'Canal', 'Delay_Magasin', 'Frequency_Magasin', 'MOQ_Magasin', 'Code_Magasin']]\n",
        "\n",
        "# Map the 'Entrepot' column based on the 'Marche' column values\n",
        "df_flux_local.loc[:, 'Entrepot'] = df_flux_local['Marche'].map(lambda x: x if x not in list_not_local_entrepot else \"Central\")\n",
        "\n",
        "# Reset index, drop duplicates, and rename columns for the local DataFrame\n",
        "df_flux_local.reset_index(drop=True, inplace=True)\n",
        "df_flux_local.drop_duplicates(inplace=True)\n",
        "df_flux_local = df_flux_local.rename(columns={'Delay_Magasin':'Delay_Entrepot', 'Frequency_Magasin':'Frequency_Entrepot', 'MOQ_Magasin':'MOQ_Entrepot', 'Code_Magasin':'Code_Entrepot'})\n",
        "\n",
        "# Filter and select columns for the central DataFrame\n",
        "df_flux_central = df_flux.loc[df_flux['Code_Monde'] != '', ['Code', 'Marche', 'Canal', 'Delay_Monde', 'Frequency_Monde', 'MOQ_Monde', 'Code_Monde']]\n",
        "\n",
        "# Drop duplicates, add 'Entrepot' column with value 'Central', reset index, and rename columns for the central DataFrame\n",
        "df_flux_central.drop_duplicates(inplace=True)\n",
        "df_flux_central['Entrepot'] = 'Central'\n",
        "df_flux_central.reset_index(drop=True, inplace=True)\n",
        "df_flux_central = df_flux_central.rename(columns={'Delay_Monde':'Delay_Entrepot', 'Frequency_Monde':'Frequency_Entrepot', 'MOQ_Monde':'MOQ_Entrepot', 'Code_Monde':'Code_Entrepot'})\n",
        "\n",
        "# Concatenate the central and local DataFrames\n",
        "df_flux_entrepot = pd.concat([df_flux_central, df_flux_local], axis=0, ignore_index=True)\n",
        "\n",
        "# dropping duplicate lines\n",
        "df_flux_entrepot = df_flux_entrepot[['Code','Canal', 'Delay_Entrepot', 'Frequency_Entrepot',\n",
        "       'MOQ_Entrepot', 'Code_Entrepot', 'Entrepot']].drop_duplicates()"
      ],
      "metadata": {
        "id": "wBjPlVQwaxwE"
      },
      "id": "wBjPlVQwaxwE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fill not available data in forecast with its mean"
      ],
      "metadata": {
        "id": "kvRzfoPThsZZ"
      },
      "id": "kvRzfoPThsZZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f1db4ba",
      "metadata": {
        "id": "8f1db4ba"
      },
      "outputs": [],
      "source": [
        "# Creating a copy of the DataFrame\n",
        "df_prev_ventes_stock_clean = df_prev_ventes_stock.copy()\n",
        "\n",
        "# If 'Historique_vente_Magasin' is less than or equal to 0 and 'Forecast_Magasin' is NaN, set 'Forecast_Magasin' to 0\n",
        "df_prev_ventes_stock_clean.loc[\n",
        "    (df_prev_ventes_stock_clean['Historique_vente_Magasin'] <= 0) & (df_prev_ventes_stock_clean['Forecast_Magasin'].isna()),\n",
        "    'Forecast_Magasin'] = 0\n",
        "\n",
        "# Calculating the mean value of 'Forecast_Magasin' respecting the product, entrepot, and year\n",
        "mean_forecast = df_prev_ventes_stock_clean[df_prev_ventes_stock_clean['Forecast_Magasin'] > 0].groupby(\n",
        "    ['Code', 'Entrepot', 'Year','Marche'])[['Forecast_Magasin']].mean().reset_index()\n",
        "\n",
        "# Creating two DataFrames: one with positive 'Forecast_Magasin' values and one with NaN 'Forecast_Magasin' values\n",
        "df_forecast_pos = df_prev_ventes_stock_clean[df_prev_ventes_stock_clean['Forecast_Magasin'] > 0].copy()\n",
        "df_forecast_nan = df_prev_ventes_stock_clean[df_prev_ventes_stock_clean['Forecast_Magasin'].isna()].copy()\n",
        "\n",
        "# Merging the DataFrame with NaN 'Forecast_Magasin' with the mean forecast values\n",
        "df_forecast_nan_mean = df_forecast_nan.drop('Forecast_Magasin', axis=1).merge(mean_forecast,\n",
        "                                                                             on=['Code', 'Entrepot', 'Year','Marche'])\n",
        "# Concatenating the DataFrames with positive 'Forecast_Magasin' and mean forecast values for NaN 'Forecast_Magasin'\n",
        "df_merge_forecast = pd.concat([df_forecast_pos, df_forecast_nan_mean]).drop('Historique_vente_Magasin', axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the mean value of 'Historique_vente_Magasin' respecting the product, entrepot, and year\n",
        "mean_ventes = df_prev_ventes_stock_clean[df_prev_ventes_stock_clean['Historique_vente_Magasin'] > 0].groupby(\n",
        "    ['Code', 'Entrepot', 'Year','Marche'])[['Historique_vente_Magasin']].mean().reset_index()\n",
        "\n",
        "# Creating two DataFrames: one with positive 'Historique_vente_Magasin' values and one with NaN 'Historique_vente_Magasin' values\n",
        "df_ventes_pos = df_prev_ventes_stock_clean[df_prev_ventes_stock_clean['Historique_vente_Magasin'] > 0].copy()\n",
        "df_ventes_nan = df_prev_ventes_stock_clean[df_prev_ventes_stock_clean['Historique_vente_Magasin'].isna()].copy()\n",
        "\n",
        "# Merging the DataFrame with NaN 'Historique_vente_Magasin' with the mean forecast values\n",
        "df_ventes_nan_mean = df_ventes_nan.drop('Historique_vente_Magasin', axis=1).merge(mean_ventes,\n",
        "                                                                             on=['Code', 'Entrepot', 'Year','Marche'])\n",
        "# Concatenating the DataFrames with positive 'Historique_vente_Magasin' and mean ventes values for NaN 'Historique_vente_Magasin'\n",
        "df_merge_ventes = pd.concat([df_ventes_pos, df_ventes_nan_mean]).drop('Forecast_Magasin', axis=1)\n",
        "\n",
        "# merging both dataframes\n",
        "df_merge_ventes_forecast = df_merge_ventes.merge(df_merge_forecast, on=['Code', 'Marche', 'Year', 'Month', 'Canal',\n",
        "       'Code_Magasin', 'Date', 'Entrepot',\n",
        "       'Stock'])"
      ],
      "metadata": {
        "id": "ahKobvbaLWDa"
      },
      "id": "ahKobvbaLWDa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Joining data in entrepôt central and local"
      ],
      "metadata": {
        "id": "QX2Y_WN2njwW"
      },
      "id": "QX2Y_WN2njwW"
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling NaN values in the 'Code_Magasin' column with an empty string\n",
        "df_merge_ventes_forecast.Code_Magasin = df_merge_ventes_forecast.Code_Magasin.fillna(\"\")\n",
        "\n",
        "# Grouping by multiple columns and aggregating the sum of 'Forecast_Magasin' and 'Historique_vente_Magasin'\n",
        "df_forecast_local_central = df_merge_ventes_forecast.groupby([\n",
        "    'Code', 'Year', 'Month', 'Entrepot', 'Canal', 'Code_Magasin', 'Date', 'Stock']).aggregate({\n",
        "    'Forecast_Magasin': 'sum',\n",
        "    'Historique_vente_Magasin': 'sum'}).reset_index()\n",
        "\n",
        "# Dropping duplicates from the resulting DataFrame\n",
        "df_forecast_local_central.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "Vw3zlaMUiYsu"
      },
      "id": "Vw3zlaMUiYsu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate the Standard deviation"
      ],
      "metadata": {
        "id": "dCXxnfK9hbv-"
      },
      "id": "dCXxnfK9hbv-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7729a92d",
      "metadata": {
        "id": "7729a92d"
      },
      "outputs": [],
      "source": [
        "# Creating a copy of the DataFrame\n",
        "df_merge_forecast_clean = df_forecast_local_central.copy()\n",
        "\n",
        "# Merging with additional information from df_base_article\n",
        "df_forecast_article = df_merge_forecast_clean.merge(df_base_article[['Code','Prix_de_vente','PRI','Classe_base']], on='Code')\n",
        "\n",
        "# Calculating revenue for historical and forecasted sales\n",
        "df_forecast_article['Revenue_historic'] = df_forecast_article['Historique_vente_Magasin'] * df_forecast_article['Prix_de_vente']\n",
        "df_forecast_article['Revenue_forecasted'] = df_forecast_article['Forecast_Magasin'] * df_forecast_article['Prix_de_vente']\n",
        "\n",
        "# Selecting only data with positive values for both 'Historique_vente_Magasin' and 'Forecast_Magasin'\n",
        "df_diff = df_forecast_article.loc[(df_forecast_article.Historique_vente_Magasin > 0) & (df_forecast_article.Forecast_Magasin > 0)][[\n",
        "    'Code', 'Historique_vente_Magasin', 'Entrepot', 'Forecast_Magasin', 'Revenue_historic', 'Revenue_forecasted', 'Year', 'Month']].copy()\n",
        "\n",
        "# Calculating standard deviation for quantity and revenue differences\n",
        "df_diff['Std_deviation_qty'] = df_diff['Forecast_Magasin'] - df_diff['Historique_vente_Magasin']\n",
        "df_diff['Std_deviation_rev'] = df_diff['Revenue_forecasted'] - df_diff['Revenue_historic']\n",
        "\n",
        "# Grouping by 'Code', 'Entrepot', and 'Year' and calculating standard deviation for quantity and revenue differences\n",
        "df_diff_std = df_diff.groupby(['Code', 'Entrepot', 'Year'])[['Std_deviation_qty', 'Std_deviation_rev']].std().reset_index()\n",
        "\n",
        "# Merging DataFrames\n",
        "df_base_std = pd.merge(df_forecast_article, df_diff_std, on=['Entrepot', 'Code', 'Year'])\n",
        "\n",
        "# Filtering out rows with NaN values in 'Std_deviation_qty' and 'Std_deviation_rev'\n",
        "df_base_std = df_base_std[(~df_base_std.Std_deviation_qty.isna()) & (~df_base_std.Std_deviation_rev.isna())]\n",
        "\n",
        "# adding the info of Marche for each code in df_base_std\n",
        "df_marche = df_merge_ventes_forecast[['Code','Marche','Year','Entrepot']].drop_duplicates()\n",
        "df_base_std = df_base_std.merge(df_marche, on=['Code','Year','Entrepot'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate the Stock Roulant"
      ],
      "metadata": {
        "id": "7JAp9TOjhgwl"
      },
      "id": "7JAp9TOjhgwl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ff0123",
      "metadata": {
        "id": "b3ff0123"
      },
      "outputs": [],
      "source": [
        "# Merge relevant columns from df_base_std and df_flux_entrepot DataFrames\n",
        "df_std_flux = df_base_std[['Code', 'Year', 'Month', 'Forecast_Magasin','Historique_vente_Magasin','Revenue_historic','Revenue_forecasted',\n",
        "                           'Date', 'Entrepot','Stock', 'Std_deviation_qty','Std_deviation_rev','Prix_de_vente', 'PRI', 'Classe_base']].merge(\n",
        "                               df_flux_entrepot, on=['Code','Entrepot'])\n",
        "\n",
        "# List of columns to be filled with default values and then converted to numeric\n",
        "list_cols = ['Delay_Entrepot','Frequency_Entrepot']\n",
        "\n",
        "# Replace empty strings with \"0 jrs\" and fill NaN values with \"0 jrs\"\n",
        "df_std_flux[list_cols] = df_std_flux[list_cols].replace(\"\", \"0 jrs\").fillna(\"0 jrs\")\n",
        "\n",
        "# Calculate delay based on specific columns\n",
        "df_std_delay = calculate_delay(df_std_flux, list_cols)\n",
        "\n",
        "# Calculate the mean forecast for each product, year, and entrepot\n",
        "df_mean_ventes = df_std_delay[df_std_delay.Historique_vente_Magasin > 0].groupby(['Code','Year','Entrepot'])[[\n",
        "    'Historique_vente_Magasin']].mean().reset_index().rename(columns={'Historique_vente_Magasin':'Mean_ventes'})\n",
        "\n",
        "# Merge the mean forecast back to the DataFrame\n",
        "df_stock_roulant = df_std_delay.merge(df_mean_ventes, on=['Code','Year','Entrepot'])\n",
        "\n",
        "# Calculate the stock roulant by multiplying the mean forecast in a year by frequency divided by 2\n",
        "df_stock_roulant['Stock_roulant'] = df_stock_roulant['Frequency_Entrepot']*df_stock_roulant['Mean_ventes']/2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate the ABC class for each product"
      ],
      "metadata": {
        "id": "qJtUNnerhy89"
      },
      "id": "qJtUNnerhy89"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89464d6d",
      "metadata": {
        "id": "89464d6d"
      },
      "outputs": [],
      "source": [
        "# Call a function to classify products based on quantity and revenue\n",
        "df_classes = classeABCQuantity(df_stock_roulant, 'Historique_vente_Magasin', 'Revenue_historic')[\n",
        "    ['Code', 'Year','Cumulative_Percentage', 'Classe_ABC_quantity', 'Cumulative_Percentage_revenue',\n",
        "       'Classe_ABC_revenue']].drop_duplicates(subset=['Code','Year'])\n",
        "\n",
        "# Merge the classification information back to the DataFrame\n",
        "df_merge_forecast_std = df_stock_roulant.merge(df_classes, on=['Code','Year'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update Google Sheets file"
      ],
      "metadata": {
        "id": "vEL9ulB7h-Gt"
      },
      "id": "vEL9ulB7h-Gt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7b84441",
      "metadata": {
        "id": "a7b84441"
      },
      "outputs": [],
      "source": [
        "# df to save in google sheets\n",
        "df_save = df_merge_forecast_std[['Date', 'Entrepot', 'Code',\n",
        "       'Historique_vente_Magasin', 'Forecast_Magasin', 'Stock',\n",
        "       'Std_deviation_rev',\n",
        "       'Classe_ABC_quantity',\n",
        "       'Classe_ABC_revenue', 'Canal', 'Delay_Entrepot',\n",
        "       'Frequency_Entrepot', 'Stock_roulant','Std_deviation_qty','Revenue_historic','Revenue_forecasted','Mean_ventes']]\n",
        "\n",
        "df_save.drop_duplicates(subset=['Date', 'Entrepot', 'Code'],inplace=True)\n",
        "\n",
        "# name of the google sheets\n",
        "spreadsheet = gc.open('Pole_Mews_Final')\n",
        "worksheet = spreadsheet.worksheet('Stock Roulant')\n",
        "\n",
        "df_save['Date'] = df_save['Date'].astype(str)\n",
        "df_save = df_save.fillna('')\n",
        "worksheet.update('A1', [df_save.columns.values.tolist()] + df_save.values.tolist())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}